{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyts\n",
        "!pip install --upgrade pyts"
      ],
      "metadata": {
        "id": "odgCC8ruTkCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1167dbe6-cea6-4139-e47e-42ae732d60ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyts\n",
            "  Downloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.3.2)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (67.7.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->pyts) (3.2.0)\n",
            "Installing collected packages: pyts\n",
            "Successfully installed pyts-0.13.0\n",
            "Requirement already satisfied: pyts in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.3.2)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (67.7.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->pyts) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import sys\n",
        "from scipy import stats\n",
        "from scipy.fft import fft, dct\n",
        "import pywt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import os\n",
        "from pyts.approximation import PiecewiseAggregateApproximation as PAA\n",
        "from scipy.fftpack import idct\n",
        "\n",
        "def generate_random_vectors(n, r):\n",
        "    random_vectors = np.random.normal(0, 1, size=(r, n))\n",
        "    return random_vectors\n",
        "\n",
        "def MINE(data,R,R_inv):\n",
        "\n",
        "  prod = np.matmul(data,R)\n",
        "  bitmap = np.where(prod < 0, 0, 1)\n",
        "  recon = np.matmul(bitmap,R_inv)\n",
        "  return recon\n",
        "\n",
        "\n",
        "def plot_confidence_interval(scores,method,stride,compression,type):\n",
        "    # compute mean silhouette score and confidence interval\n",
        "    mean_score = np.mean(scores)\n",
        "    ci = stats.t.interval(0.95, len(scores)-1, loc=mean_score, scale=stats.sem(scores))\n",
        "\n",
        "    # 2D array with the lower and upper bounds of the confidence interval\n",
        "    yerr = np.array([[mean_score-ci[0]], [ci[1]-mean_score]])\n",
        "\n",
        "    # create the figure and axis objects\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # plot the data with error bars\n",
        "    ax.plot(scores, marker='o')\n",
        "    ax.errorbar(x=range(len(scores)), y=scores, yerr=yerr, fmt='none', ecolor='r')\n",
        "\n",
        "    # set the axis labels and title\n",
        "    ax.set_xlabel('Subset of features')\n",
        "\n",
        "    if type == 'SC' :\n",
        "     ax.set_ylabel('ACCURACY score')\n",
        "     if method == 'RAW':\n",
        "      ax.set_title(f'ACCURACY scores with 95% confidence interval\\n M={method} , W= {stride} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "     else:\n",
        "      ax.set_title(f'ACCURACY scores with 95% confidence interval\\n M={method} , W= {stride}, C= {compression} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "\n",
        "\n",
        "    if type == 'RMSE' :\n",
        "     ax.set_ylabel('F1 score')\n",
        "     if method == 'RAW':\n",
        "      ax.set_title(f'F1 scores with 95% confidence interval\\n M={method} , W= {stride} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "     else:\n",
        "      ax.set_title(f'F1 scores with 95% confidence interval\\n M={method} , W= {stride}, C= {compression} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "    # return the figure object\n",
        "    return fig\n",
        "\n",
        "def plot_score_confidence_interval(data,window_size,compression):\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20, 4), sharey=True)  # Adjust the figure size as needed\n",
        "\n",
        "    colors = ['b', 'g', 'r', 'c', 'm']  # Colors for each method\n",
        "\n",
        "    #y_axis_limits = (-5, 5)  # axis limits\n",
        "\n",
        "    for i, (scores, method) in enumerate(data):\n",
        "        ax = axs[i]\n",
        "        n = len(scores)\n",
        "        x = np.arange(n) + 1\n",
        "        y = np.array(scores)\n",
        "\n",
        "        # Identify and count outliers based on the limits\n",
        "        outliers = np.where((y < -5) | (y > 5))[0]\n",
        "        num_outliers = len(outliers)\n",
        "\n",
        "        # Exclude outliers from the data\n",
        "        filtered_scores = np.delete(y, outliers)\n",
        "        filtered_x = np.delete(x, outliers)\n",
        "\n",
        "        mean = np.mean(filtered_scores)\n",
        "        # Calculate the confidence interval\n",
        "        ci = stats.t.interval(0.95, len(filtered_scores), loc=mean, scale=stats.sem(filtered_scores))\n",
        "        # Plot the non-outlier data points and mean\n",
        "        ax.plot(filtered_x, filtered_scores, 'o', markersize=4, color=colors[i])\n",
        "        ax.plot(x, [mean] * n, '--', color=colors[i])\n",
        "\n",
        "        fig.suptitle(f'ACCURACY scores with 95% confidence interval // W= {window_size}, C= {compression} ')\n",
        "\n",
        "        ax.set_xlabel('Window')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title(f'{method} : [{ci[0]:.5f}, {ci[1]:.5f}] ')\n",
        "        ax.grid(True)\n",
        "\n",
        "        # Set the y-axis limits\n",
        "        #ax.set_ylim(y_axis_limits)\n",
        "\n",
        "        # Add the number of outliers as text in the top right corner\n",
        "        ax.text(0.85, 0.9, f'Outliers: {num_outliers}', transform=ax.transAxes, fontsize=10, color='red', ha='right')\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_F1_confidence_interval(data,window_size,compression):\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20, 4), sharey=True)  # Adjust the figure size as needed\n",
        "\n",
        "    colors = ['b', 'g', 'r', 'c', 'm']  # Colors for each method\n",
        "\n",
        "   # y_axis_limits = (-5, 5) # Outlier limits\n",
        "\n",
        "    for i, (scores, method) in enumerate(data):\n",
        "        ax = axs[i]\n",
        "        n = len(scores)\n",
        "        x = np.arange(n) + 1\n",
        "        y = np.array(scores)\n",
        "        # Identify and count outliers based on the limits\n",
        "        outliers = np.where((y < -5) | (y > 5))[0]\n",
        "        num_outliers = len(outliers)\n",
        "\n",
        "        # Exclude outliers from the data\n",
        "        filtered_scores = np.delete(y, outliers)\n",
        "        filtered_x = np.delete(x, outliers)\n",
        "\n",
        "        mean = np.mean(filtered_scores)\n",
        "        # Calculate the confidence interval\n",
        "        ci = stats.t.interval(0.95, len(filtered_scores), loc=mean, scale=stats.sem(filtered_scores))\n",
        "\n",
        "        # Plot the non-outlier data points and mean\n",
        "        ax.plot(filtered_x, filtered_scores, 'o', markersize=4, color=colors[i])\n",
        "        ax.plot(x, [mean] * n, '--', color=colors[i])\n",
        "\n",
        "        fig.suptitle(f'F1 scores with 95% confidence interval // W= {window_size}, C= {compression} ')\n",
        "\n",
        "        ax.set_xlabel('Window')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title(f'{method} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "        ax.grid(True)\n",
        "\n",
        "        # Set the y-axis limits to the predefined range\n",
        "       # ax.set_ylim(y_axis_limits)\n",
        "\n",
        "        # Add the number of outliers as text in the top right corner\n",
        "        ax.text(0.85, 0.9, f'Outliers: {num_outliers}', transform=ax.transAxes, fontsize=10, color='red', ha='right')\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/pump_sensor2.txt', delimiter=',')\n",
        "\n",
        "# BROKEN,NORMAL,RECOVERING -> 0,0.5,1\n",
        "le = LabelEncoder()\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
        "max_label = df.iloc[:, -1].max()\n",
        "df.iloc[:, -1] = df.iloc[:, -1] / max_label * 1.0\n",
        "# Discard the first row + first two columns\n",
        "df = df.iloc[:, 2:]\n",
        "data = df.to_numpy(dtype='float')\n",
        "# Split  features (X) and target (y)\n",
        "X = data[:, :-1]\n",
        "#print(X)\n",
        "y = data[:, -1]\n",
        "#print(y[0])\n",
        "# Fill Nan values based on the mean of each sensor\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "# Select 1000 0.5 kai 1 labels\n",
        "label_05_indices = np.where(y == 0.5)[0]\n",
        "label_1_indices = np.where(y == 1)[0]\n",
        "label_05_indices = np.random.choice(label_05_indices, size=1000, replace=False)\n",
        "label_1_indices = np.random.choice(label_1_indices, size=1000, replace=False)\n",
        "# Concatenate + shuffle\n",
        "indices = np.concatenate((label_05_indices, label_1_indices))\n",
        "np.random.seed(123)   #Gia idio dataset shuffle se ola ta algorithms\n",
        "np.random.shuffle(indices)\n",
        "X= X[indices]\n",
        "y= y[indices]\n",
        "y[y == 0.5] = 0\n",
        "\n",
        "# unique_labels, label_counts = np.unique(y, return_counts=True)\n",
        "# for i in range(len(unique_labels)):\n",
        "#    print(f\"Label {unique_labels[i]}: {label_counts[i]}\")\n",
        "# X = imputer.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "# window size, etc.\n",
        "window_sizes = [16, 32, 64, 128]\n",
        "compressions = [4, 8, 16]\n",
        "methods = ['DFT', 'DCT', 'DWT', 'PAA','MINE']\n",
        "\n",
        "#file for storing\n",
        "folder_name = f\"LOGISTIC Regression new PUMP Measurements\"\n",
        "if not os.path.exists(folder_name):\n",
        "   os.makedirs(folder_name)\n",
        "\n",
        "raw_folder_name = f\"RAW DATA\"\n",
        "if not os.path.exists(os.path.join(folder_name,raw_folder_name)):\n",
        "   os.makedirs(os.path.join(folder_name,raw_folder_name))\n",
        "pdf_file = os.path.join(folder_name,raw_folder_name, 'plots.pdf')\n",
        "\n",
        "with PdfPages(pdf_file, 'a') as pdf:\n",
        "  for window_size in window_sizes:\n",
        "\n",
        "     # lists to store metrics for each window\n",
        "     f1_list = []\n",
        "     accuracy_list = []\n",
        "     num =int( window_size+window_size/4)\n",
        "\n",
        "     # Iterate over the windows\n",
        "     for i in range(0, len(X)-window_size*2+1, window_size):\n",
        "\n",
        "          # Split the data into training and testing sets\n",
        "          X_train = X[i:i+window_size]\n",
        "          X_test = X[i+window_size:i+num]\n",
        "          y_train = y[i:i+window_size]\n",
        "          y_test = y[i+window_size:i+num]\n",
        "          #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "          # Data scaling\n",
        "          sc = MinMaxScaler()\n",
        "          X_train_scaled = sc.fit_transform(X_train)\n",
        "          X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "          #print(X_train_scaled[0], X_test_scaled[0], y_train_scaled[0], y_test_scaled[0])\n",
        "\n",
        "          # Model application\n",
        "          log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        "          log_reg.fit(X_train_scaled, y_train)\n",
        "          # Generate predictions\n",
        "          y_pred_scaled = log_reg.predict(X_test_scaled)\n",
        "\n",
        "          # performance\n",
        "          accuracy = accuracy_score(y_test, y_pred_scaled)\n",
        "          accuracy_list.append(accuracy)\n",
        "          f1 = f1_score(y_test, y_pred_scaled)\n",
        "          f1_list.append(f1)\n",
        "\n",
        "     #store plots\n",
        "     methd = 'RAW'\n",
        "     comprsn = 0\n",
        "     fig = plot_confidence_interval(accuracy_list,methd,window_size ,comprsn,'SC') #plot function call\n",
        "     pdf.savefig(fig)\n",
        "     plt.close(fig)\n",
        "\n",
        "     fig2 = plot_confidence_interval(f1_list,methd,window_size ,comprsn,'RMSE') #plot function call\n",
        "     pdf.savefig(fig2)\n",
        "     plt.close(fig2)\n",
        "\n",
        "     # create a file name based on the method, subset index, stride, and compression\n",
        "     avg_accuracy = np.mean(accuracy_list)\n",
        "     file_name = f\"Window size({window_size}) - accuracy-scores.txt\"\n",
        "     with open(os.path.join(folder_name,raw_folder_name, file_name), 'w+') as f:\n",
        "              f.write(f\"Average accuracy Score: {avg_accuracy}\\n\")\n",
        "              content = str(accuracy_list)\n",
        "              f.write(content)\n",
        "              f.close()\n",
        "\n",
        "     avg_f1 = np.mean(f1_list)\n",
        "     file_name = f\"Window size({window_size}) - f1 scores).txt\"\n",
        "     with open(os.path.join(folder_name,raw_folder_name, file_name), 'w+') as f:\n",
        "              f.write(f\"Average f1 Score: {avg_f1}\\n\")\n",
        "              content = str(f1_list)\n",
        "              f.write(content)\n",
        "              f.close()\n",
        "\n",
        "for window_size in window_sizes:\n",
        "\n",
        "    #file for storing\n",
        "    stride_folder_name = f\"stride({window_size})\"\n",
        "    if not os.path.exists(os.path.join(folder_name,stride_folder_name)):\n",
        "        os.makedirs(os.path.join(folder_name,stride_folder_name))\n",
        "\n",
        "    for compression in compressions:\n",
        "\n",
        "        # #vector and inverse vector arrays for our algorithm\n",
        "        n = 64*int(window_size/compression)  # Dimension of each random vector\n",
        "        r = 51  # Number of random vectors to generate/rows\n",
        "        R = generate_random_vectors(n, r)\n",
        "        R_inv= np.linalg.pinv(R)\n",
        "\n",
        "        #files for storing measurements\n",
        "        compression_folder_name = f\"compression({compression})\"\n",
        "        if not os.path.exists(os.path.join(folder_name,stride_folder_name, compression_folder_name)):\n",
        "            os.makedirs(os.path.join(folder_name,stride_folder_name, compression_folder_name))\n",
        "\n",
        "        #files for storing plots\n",
        "        plots_dir = os.path.join(folder_name,stride_folder_name, compression_folder_name, 'plots')\n",
        "        os.makedirs(plots_dir, exist_ok=True)\n",
        "        pdf_file = os.path.join(plots_dir, 'plots.pdf')\n",
        "\n",
        "        with PdfPages(pdf_file, 'a') as pdf:\n",
        "            results1 = []\n",
        "            results2 = []\n",
        "            for method in methods:\n",
        "\n",
        "                slices = window_size // compression\n",
        "\n",
        "                # lists to store metrics for each window\n",
        "                f1_list = []\n",
        "                accuracy_list = []\n",
        "                num =int( window_size+window_size/4)\n",
        "\n",
        "                # Iterate over the windows\n",
        "                for i in range(0, len(X)-window_size*2+1, window_size):\n",
        "\n",
        "                   # Split the data into training and testing sets\n",
        "                   X_train = X[i:i+window_size]\n",
        "                   X_test = X[i+window_size:i+num]\n",
        "                   y_train = y[i:i+window_size]\n",
        "                   y_test = y[i+window_size:i+num]\n",
        "                  # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "                   # Data scaling\n",
        "                   sc = MinMaxScaler()\n",
        "                   X_train_scaled = sc.fit_transform(X_train)\n",
        "                   X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "                   #print(X_train_scaled[0], X_test_scaled[0], y_train_scaled[0], y_test_scaled[0])\n",
        "\n",
        "                   #vector and inverse vector arrays for our algorithm\n",
        "                  #  n = 64*int(window_size/compression)  # Dimension of each random vector\n",
        "                  #  r = 51  # Number of random vectors to generate/rows\n",
        "                  #  R = generate_random_vectors(n, r)\n",
        "                  #  R_inv= np.linalg.pinv(R)\n",
        "\n",
        "                   if method == 'DFT':\n",
        "\n",
        "                       #array to store the restored data\n",
        "                       compressed_X_train_scaled = np.zeros_like(X_train_scaled)\n",
        "\n",
        "                       for i in range(window_size):\n",
        "                          # Compute abs DFT of each row\n",
        "                          dft_X_train_scaled  =  np.fft.fft(X_train_scaled[i])\n",
        "                          # Sort the DFT coefficients along each row by their magnitude\n",
        "                          sorted_indices = np.argsort(-np.abs(dft_X_train_scaled))[:slices]\n",
        "                          sorted_dft_X_train_scaled = dft_X_train_scaled[sorted_indices]\n",
        "                          # Keep  top  coeff\n",
        "                          top__dft_X_train_scaled = sorted_dft_X_train_scaled[:slices]\n",
        "                          #reconstruct the compressed dataset\n",
        "                          compressed_X_train_scaled[i] = np.fft.ifft(top__dft_X_train_scaled,51).real\n",
        "\n",
        "                       #array to store the restored data\n",
        "                       compressed_X_test_scaled = np.zeros_like(X_test_scaled)\n",
        "\n",
        "                       for i in range(int(window_size/4)):\n",
        "                          # Compute abs DFT of each row\n",
        "                          dft_X_test_scaled =  np.fft.fft(X_test_scaled[i])\n",
        "                          # Sort the DFT coefficients along each row by their magnitude\n",
        "                          sorted_indices = np.argsort(np.abs(dft_X_test_scaled))[::-1][:slices]\n",
        "                          sorted_dft_X_test_scaled = dft_X_test_scaled[sorted_indices]\n",
        "                          # Keep  top  coeff\n",
        "                          top__dft_X_test_scaled = sorted_dft_X_test_scaled[:slices]\n",
        "                          #reconstruct the compressed dataset\n",
        "                          compressed_X_test_scaled[i] = np.fft.ifft(top__dft_X_test_scaled,51).real\n",
        "\n",
        "                   elif method == 'DCT':\n",
        "\n",
        "                       #array to store the restored data\n",
        "                       compressed_X_train_scaled = np.zeros_like(X_train_scaled)\n",
        "\n",
        "                       for i in range(window_size):\n",
        "                          # Compute abs DCT of each row\n",
        "                          dct_X_train_scaled  =  dct(X_train_scaled[i])\n",
        "                          # Sort the DCT coefficients along each row by their magnitude\n",
        "                          sorted_indices = np.argsort(-np.abs(dct_X_train_scaled))[:slices]\n",
        "                          sorted_dct_X_train_scaled = dct_X_train_scaled[sorted_indices]\n",
        "                          # Keep  top  coeff\n",
        "                          top__dct_X_train_scaled = sorted_dct_X_train_scaled[:slices]\n",
        "                          #reconstruct the compressed dataset\n",
        "                          compressed_X_train_scaled[i] = idct(top__dct_X_train_scaled ,type = 2, n = 51).real\n",
        "\n",
        "                       #array to store the restored data\n",
        "                       compressed_X_test_scaled = np.zeros_like(X_test_scaled)\n",
        "\n",
        "                       for i in range(int(window_size/4)):\n",
        "                          # Compute abs DCT of each row\n",
        "                          dct_X_test_scaled =  dct(X_test_scaled[i])\n",
        "                          # Sort the DCT coefficients along each row by their magnitude\n",
        "                          sorted_indices = np.argsort(-np.abs(dct_X_test_scaled))[:slices]\n",
        "                          sorted_dct_X_test_scaled = dct_X_test_scaled[sorted_indices]\n",
        "                          # Keep  top  coeff\n",
        "                          top__dct_X_test_scaled = sorted_dct_X_test_scaled[:slices]\n",
        "                          #reconstruct the compressed dataset\n",
        "                          compressed_X_test_scaled[i] = idct(top__dct_X_test_scaled ,type = 2 , n = 51).real\n",
        "\n",
        "                   elif method == 'DWT':\n",
        "\n",
        "                      #array to store the restored data\n",
        "                      compressed_X_train_scaled = np.zeros_like(X_train_scaled)\n",
        "                      compressed_X_train_scaled = np.pad(compressed_X_train_scaled, ((0, 0), (0, 1)), 'constant', constant_values=0)\n",
        "                      for i in range(window_size):\n",
        "                          # Apply DWT to each row using 'db1' wavelet\n",
        "                          cA, cD = pywt.dwt(X_train_scaled[i], 'db1')\n",
        "                          # Sort\n",
        "                          sorted_cD_subset_data = np.zeros_like(cD) #initialize storage array\n",
        "                          sorted_indices = np.argsort(-np.abs(cD))[:slices]\n",
        "                          sorted_cD_subset_data[sorted_indices] = cD[sorted_indices]\n",
        "                          # Perform inverse DWT to restore the row\n",
        "                          compressed_X_train_scaled[i] = pywt.idwt(cA, sorted_cD_subset_data, 'db1')\n",
        "\n",
        "                      #array to store the restored data\n",
        "                      compressed_X_test_scaled = np.zeros_like(X_test_scaled)\n",
        "                      compressed_X_test_scaled = np.pad(compressed_X_test_scaled, ((0, 0), (0, 1)), 'constant', constant_values=0)\n",
        "                      for i in range(int(window_size/4)):\n",
        "                          # Apply DWT to each row using 'db1' wavelet\n",
        "                          cA, cD = pywt.dwt(X_test_scaled[i], 'db1')\n",
        "                          # Sort\n",
        "                          sorted_cD_subset_data = np.zeros_like(cD) #initialize storage array\n",
        "                          sorted_indices = np.argsort(-np.abs(cD))[:slices]\n",
        "                          sorted_cD_subset_data[sorted_indices] = cD[sorted_indices]\n",
        "                          # Perform inverse DWT to restore the row\n",
        "                          compressed_X_test_scaled[i] = pywt.idwt(cA, sorted_cD_subset_data, 'db1')\n",
        "\n",
        "                   elif method == 'PAA':\n",
        "                      # Apply PAA along the rows of the array\n",
        "                      paa = PAA(window_size = compression)\n",
        "                      compressed_X_train_scaled = paa.fit_transform(X_train_scaled)\n",
        "                      compressed_X_test_scaled = paa.fit_transform(X_test_scaled)\n",
        "\n",
        "                   elif method == 'MINE':\n",
        "\n",
        "                      #array to store the restored data\n",
        "                      compressed_X_train_scaled = np.zeros_like(X_train_scaled)\n",
        "\n",
        "                      for i in range(window_size):\n",
        "                        row = X_train_scaled[i]\n",
        "                        # Apply my algorithm along the rows of the array\n",
        "                        compressed_X_train_scaled[i] = MINE(row,R,R_inv)\n",
        "\n",
        "                      #array to store the restored data\n",
        "                      compressed_X_test_scaled = np.zeros_like(X_test_scaled)\n",
        "                      for i in range(int(window_size/4)):\n",
        "                        row = X_test_scaled[i]\n",
        "                        # Apply my algorithm along the rows of the array\n",
        "                        compressed_X_test_scaled[i] = MINE(row,R,R_inv)\n",
        "\n",
        "                   # Model application\n",
        "                  # print(compressed_X_train_scaled.shape)\n",
        "                   regressor = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        "                   regressor.fit(compressed_X_train_scaled, y_train)\n",
        "\n",
        "                   # Generate predictions\n",
        "                   y_pred_scaled = regressor.predict(compressed_X_test_scaled)\n",
        "\n",
        "                   # performance (mean squared error, mean absolute error, and R-squared score)\n",
        "                   accuracy = accuracy_score(y_test, y_pred_scaled)\n",
        "                   accuracy_list.append(accuracy)\n",
        "                   f1 = f1_score(y_test, y_pred_scaled)\n",
        "                   f1_list.append(f1)\n",
        "\n",
        "                results1.append((accuracy_list, method))\n",
        "                results2.append((f1_list, method))\n",
        "\n",
        "                # create a file name based on the method, subset index, stride, and compression\n",
        "                avg_accuracy = np.mean(accuracy_list)\n",
        "                file_name = f\"{method}_window size({window_size})_compression({compression} - ACCURACY SCORES).txt\"\n",
        "                with open(os.path.join(folder_name,stride_folder_name, compression_folder_name, file_name), 'w+') as f:\n",
        "                   f.write(f\"Average accuracy Score: {avg_accuracy}\\n\")\n",
        "                   content = str(accuracy_list)\n",
        "                   f.write(content)\n",
        "                   f.close()\n",
        "\n",
        "                avg_f1 = np.mean(f1_list)\n",
        "                file_name = f\"{method}_window size({window_size})_compression({compression} - f1 SCORES).txt\"\n",
        "                with open(os.path.join(folder_name,stride_folder_name, compression_folder_name, file_name), 'w+') as f:\n",
        "                   f.write(f\"Average f1 Score: {avg_f1}\\n\")\n",
        "                   content = str(f1_list)\n",
        "                   f.write(content)\n",
        "                   f.close()\n",
        "            #store plots\n",
        "            fig = plot_score_confidence_interval(results1,window_size,compression) #plot function call\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "            fig = plot_F1_confidence_interval(results2,window_size,compression) #plot function call\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n"
      ],
      "metadata": {
        "id": "Ao3xo8R4P4X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96de156-46f3-41cf-ecf2-c881bd40f360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f05600c96030>:158: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GIA 3 LABELS, ALLA 0,1,2 OXI 0,0.5,1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import sys\n",
        "from scipy import stats\n",
        "from scipy.fft import fft, dct\n",
        "import pywt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import os\n",
        "from pyts.approximation import PiecewiseAggregateApproximation as PAA\n",
        "from scipy.fftpack import idct\n",
        "\n",
        "def plot_confidence_interval(scores,method,stride,compression,type):\n",
        "    # compute mean silhouette score and confidence interval\n",
        "    mean_score = np.mean(scores)\n",
        "    ci = stats.t.interval(0.95, len(scores)-1, loc=mean_score, scale=stats.sem(scores))\n",
        "\n",
        "    # 2D array with the lower and upper bounds of the confidence interval\n",
        "    yerr = np.array([[mean_score-ci[0]], [ci[1]-mean_score]])\n",
        "\n",
        "    # create the figure and axis objects\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # plot the data with error bars\n",
        "    ax.plot(scores, marker='o')\n",
        "    ax.errorbar(x=range(len(scores)), y=scores, yerr=yerr, fmt='none', ecolor='r')\n",
        "\n",
        "    # set the axis labels and title\n",
        "    ax.set_xlabel('Subset of features')\n",
        "\n",
        "    if type == 'SC' :\n",
        "     ax.set_ylabel('ACCURACY score')\n",
        "     if method == 'RAW':\n",
        "      ax.set_title(f'ACCURACY scores with 95% confidence interval\\n M={method} , W= {stride} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "     else:\n",
        "      ax.set_title(f'ACCURACY scores with 95% confidence interval\\n M={method} , W= {stride}, C= {compression} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "\n",
        "\n",
        "    if type == 'RMSE' :\n",
        "     ax.set_ylabel('F1 score')\n",
        "     if method == 'RAW':\n",
        "      ax.set_title(f'F1 scores with 95% confidence interval\\n M={method} , W= {stride} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "     else:\n",
        "      ax.set_title(f'F1 scores with 95% confidence interval\\n M={method} , W= {stride}, C= {compression} : [{ci[0]:.5f}, {ci[1]:.5f}]')\n",
        "    # return the figure object\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/pump_sensor2.txt', delimiter=',')\n",
        "\n",
        "# BROKEN,NORMAL,RECOVERING -> 0,0.5,1\n",
        "le = LabelEncoder()\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
        "max_label = df.iloc[:, -1].max()\n",
        "df.iloc[:, -1] = df.iloc[:, -1]\n",
        "# Discard the first row + first two columns\n",
        "df = df.iloc[:, 2:]\n",
        "data = df.to_numpy(dtype='float')\n",
        "# Split  features (X) and target (y)\n",
        "X = data[:, :-1]\n",
        "#print(X)\n",
        "y = data[:, -1]\n",
        "#print(y[0])\n",
        "# Fill Nan values based on the mean of each sensor\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "# Select 1000 0.5 kai 1 labels\n",
        "label_0_indices = np.where(y == 0)[0]\n",
        "label_05_indices = np.where(y == 1)[0]\n",
        "label_1_indices = np.where(y == 2)[0]\n",
        "label_05_indices = np.random.choice(label_05_indices, size=1000, replace=False)\n",
        "label_1_indices = np.random.choice(label_1_indices, size=1000, replace=False)\n",
        "# Concatenate + shuffle\n",
        "indices = np.concatenate((label_0_indices,label_05_indices, label_1_indices))\n",
        "np.random.seed(123)   #Gia idio dataset shuffle se ola ta algorithms\n",
        "np.random.shuffle(indices)\n",
        "X= X[indices]\n",
        "y= y[indices]\n",
        "\n",
        "# unique_labels, label_counts = np.unique(y, return_counts=True)\n",
        "# for i in range(len(unique_labels)):\n",
        "#    print(f\"Label {unique_labels[i]}: {label_counts[i]}\")\n",
        "# X = imputer.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "# window size, etc.\n",
        "window_sizes = [16, 32, 64, 128]\n",
        "compressions = [4, 8, 16]\n",
        "methods = ['DFT', 'DCT', 'DWT', 'PAA']\n",
        "\n",
        "#file for storing\n",
        "folder_name = f\"LOGISTIC Regression PUMP Measurements\"\n",
        "if not os.path.exists(folder_name):\n",
        "   os.makedirs(folder_name)\n",
        "\n",
        "raw_folder_name = f\"RAW DATA\"\n",
        "if not os.path.exists(os.path.join(folder_name,raw_folder_name)):\n",
        "   os.makedirs(os.path.join(folder_name,raw_folder_name))\n",
        "pdf_file = os.path.join(folder_name,raw_folder_name, 'plots.pdf')\n",
        "\n",
        "with PdfPages(pdf_file, 'a') as pdf:\n",
        "  for window_size in window_sizes:\n",
        "\n",
        "     # lists to store metrics for each window\n",
        "     f1_list = []\n",
        "     accuracy_list = []\n",
        "     num =int( window_size+window_size/4)\n",
        "\n",
        "     # Iterate over the windows\n",
        "     for i in range(0, len(X)-window_size*2+1, window_size):\n",
        "\n",
        "          # Split the data into training and testing sets\n",
        "          X_train = X[i:i+window_size]\n",
        "          X_test = X[i+window_size:i+num]\n",
        "          y_train = y[i:i+window_size]\n",
        "          y_test = y[i+window_size:i+num]\n",
        "          #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "          # Data scaling\n",
        "          sc = MinMaxScaler()\n",
        "          X_train_scaled = sc.fit_transform(X_train)\n",
        "          X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "          #print(X_train_scaled[0], X_test_scaled[0], y_train_scaled[0], y_test_scaled[0])\n",
        "\n",
        "          # Model application\n",
        "          log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        "          log_reg.fit(X_train_scaled, y_train)\n",
        "          # Generate predictions\n",
        "          y_pred_scaled = log_reg.predict(X_test_scaled)\n",
        "\n",
        "          # performance\n",
        "          accuracy = accuracy_score(y_test, y_pred_scaled)\n",
        "          accuracy_list.append(accuracy)\n",
        "          f1 = f1_score(y_test, y_pred_scaled,average = 'micro')\n",
        "          f1_list.append(f1)\n",
        "\n",
        "     #store plots\n",
        "     methd = 'RAW'\n",
        "     comprsn = 0\n",
        "     fig = plot_confidence_interval(accuracy_list,methd,window_size ,comprsn,'SC') #plot function call\n",
        "     pdf.savefig(fig)\n",
        "     plt.close(fig)\n",
        "\n",
        "     fig2 = plot_confidence_interval(f1_list,methd,window_size ,comprsn,'RMSE') #plot function call\n",
        "     pdf.savefig(fig2)\n",
        "     plt.close(fig2)\n",
        "\n",
        "     # create a file name based on the method, subset index, stride, and compression\n",
        "     avg_accuracy = np.mean(accuracy_list)\n",
        "     file_name = f\"Window size({window_size}) - accuracy-scores.txt\"\n",
        "     with open(os.path.join(folder_name,raw_folder_name, file_name), 'w+') as f:\n",
        "              f.write(f\"Average accuracy Score: {avg_accuracy}\\n\")\n",
        "              content = str(accuracy_list)\n",
        "              f.write(content)\n",
        "              f.close()\n",
        "\n",
        "     avg_f1 = np.mean(f1_list)\n",
        "     file_name = f\"Window size({window_size}) - f1 scores).txt\"\n",
        "     with open(os.path.join(folder_name,raw_folder_name, file_name), 'w+') as f:\n",
        "              f.write(f\"Average f1 Score: {avg_f1}\\n\")\n",
        "              content = str(f1_list)\n",
        "              f.write(content)\n",
        "              f.close()\n",
        "\n",
        "for window_size in window_sizes:\n",
        "\n",
        "    #file for storing\n",
        "    stride_folder_name = f\"stride({window_size})\"\n",
        "    if not os.path.exists(os.path.join(folder_name,stride_folder_name)):\n",
        "        os.makedirs(os.path.join(folder_name,stride_folder_name))\n",
        "\n",
        "    for compression in compressions:\n",
        "\n",
        "        #files for storing measurements\n",
        "        compression_folder_name = f\"compression({compression})\"\n",
        "        if not os.path.exists(os.path.join(folder_name,stride_folder_name, compression_folder_name)):\n",
        "            os.makedirs(os.path.join(folder_name,stride_folder_name, compression_folder_name))\n",
        "\n",
        "        #files for storing plots\n",
        "        plots_dir = os.path.join(folder_name,stride_folder_name, compression_folder_name, 'plots')\n",
        "        os.makedirs(plots_dir, exist_ok=True)\n",
        "        pdf_file = os.path.join(plots_dir, 'plots.pdf')\n",
        "\n",
        "        with PdfPages(pdf_file, 'a') as pdf:\n",
        "            for method in methods:\n",
        "\n",
        "                slices = window_size // compression\n",
        "\n",
        "                # lists to store metrics for each window\n",
        "                f1_list = []\n",
        "                accuracy_list = []\n",
        "                num =int( window_size+window_size/4)\n",
        "\n",
        "                # Iterate over the windows\n",
        "                for i in range(0, len(X)-window_size*2+1, window_size):\n",
        "\n",
        "                   # Split the data into training and testing sets\n",
        "                   X_train = X[i:i+window_size]\n",
        "                   X_test = X[i+window_size:i+num]\n",
        "                   y_train = y[i:i+window_size]\n",
        "                   y_test = y[i+window_size:i+num]\n",
        "                  # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "                   # Data scaling\n",
        "                   sc = MinMaxScaler()\n",
        "                   X_train_scaled = sc.fit_transform(X_train)\n",
        "                   X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "                   #print(X_train_scaled[0], X_test_scaled[0], y_train_scaled[0], y_test_scaled[0])\n",
        "\n",
        "                   if method == 'DFT':\n",
        "\n",
        "                       # Compute abs DFT of each row of X_train\n",
        "                       dft_X_train_scaled = np.fft.fft(X_train_scaled, axis=1)\n",
        "                       abs_dft_X_train_scaled = np.abs(dft_X_train_scaled)\n",
        "                       # Sort ROWS\n",
        "                       sorted_dft_X_train_scaled = np.sort(abs_dft_X_train_scaled, axis=1)[:, ::-1]\n",
        "                       # Keep  top  coeff\n",
        "                       top4_dft_X_train_scaled = sorted_dft_X_train_scaled[:, :slices]\n",
        "                       #reconstruct the compressed dataset\n",
        "                       compressed_X_train_scaled = np.fft.ifft(top4_dft_X_train_scaled, axis=1).real\n",
        "\n",
        "                       # Compute abs DFT of each row of X_test\n",
        "                       dft_X_test_scaled = np.fft.fft(X_test_scaled, axis=1)\n",
        "                       abs_dft_X_test_scaled = np.abs(dft_X_test_scaled)\n",
        "                       # Sort ROWS\n",
        "                       sorted_dft_X_test_scaled = np.sort(abs_dft_X_test_scaled, axis=1)[:, ::-1]\n",
        "                       # Keep  top  coeff\n",
        "                       top4_dft_X_test_scaled = sorted_dft_X_test_scaled[:, :slices]\n",
        "                       #reconstruct the compressed dataset\n",
        "                       compressed_X_test_scaled = np.fft.ifft(top4_dft_X_test_scaled, axis=1).real\n",
        "\n",
        "                   elif method == 'DCT':\n",
        "\n",
        "                       # Compute DCT of each row of X_train\n",
        "                       dct_X_train_scaled = dct(X_train_scaled, axis=1)\n",
        "                       # Sort ROWS\n",
        "                       sorted_dct_X_train_scaled = np.sort(np.abs(dct_X_train_scaled), axis=1)[:, ::-1]\n",
        "                       # Keep  top  coeff\n",
        "                       top4_dct_X_train_scaled = sorted_dct_X_train_scaled[:, :slices]\n",
        "                       #reconstruct the compressed dataset\n",
        "                       compressed_X_train_scaled = idct(top4_dct_X_train_scaled, axis=1).real\n",
        "\n",
        "                       # Compute abs DFT of each row of X_test\n",
        "                       dct_X_test_scaled = dct(X_test_scaled, axis=1)\n",
        "                       # Sort ROWS\n",
        "                       sorted_dct_X_test_scaled = np.sort(np.abs(dct_X_test_scaled), axis=1)[:, ::-1]\n",
        "                       # Keep  top  coeff\n",
        "                       top4_dct_X_test_scaled = sorted_dct_X_test_scaled[:, :slices]\n",
        "                       #reconstruct the compressed dataset\n",
        "                       compressed_X_test_scaled = idct(top4_dct_X_test_scaled, axis=1).real\n",
        "\n",
        "                      #  print('be4',X_train_scaled[0],X_train_scaled[1])\n",
        "                      #  print('dct',dct_X_train_scaled.shape,dct_X_train_scaled[0],dct_X_train_scaled[1])\n",
        "                      #  print('comped',top4_dct_X_train_scaled[0], top4_dct_X_train_scaled[1])\n",
        "                      #  print('reconed',compressed_X_train_scaled.shape,compressed_X_train_scaled[0],compressed_X_train_scaled[1])\n",
        "\n",
        "                   elif method == 'DWT':\n",
        "\n",
        "                      # Apply DWT to X_train_scaled\n",
        "                      cA, cD = pywt.dwt(X_train_scaled, 'db1', axis=1)\n",
        "                      # Sort ROWS\n",
        "                      sorted_cA = np.sort(np.abs(cA), axis=1)[:, ::-1]\n",
        "                      # select biggest coefficients\n",
        "                      X_train_compressed = sorted_cA[:, :slices]\n",
        "                      # Reconstruct original data\n",
        "                      compressed_X_train_scaled = pywt.idwt(X_train_compressed, None, 'db1')\n",
        "\n",
        "                      # Apply DWT to X_train_scaled\n",
        "                      cA, cD = pywt.dwt(X_test_scaled, 'db1', axis=1)\n",
        "                      # Sort ROWS\n",
        "                      sorted_cA = np.sort(np.abs(cA), axis=1)[:, ::-1]\n",
        "                      # select biggest coefficients\n",
        "                      X_test_compressed = sorted_cA[:, :slices]\n",
        "                      # Reconstruct original data\n",
        "                      compressed_X_test_scaled = pywt.idwt(X_test_compressed, None, 'db1')\n",
        "\n",
        "                   elif method == 'PAA':\n",
        "                      # Apply PAA along the rows of the array\n",
        "                      paa = PAA(window_size = slices)\n",
        "                      compressed_X_train_scaled = paa.fit_transform(X_train_scaled)\n",
        "                      compressed_X_test_scaled = paa.fit_transform(X_test_scaled)\n",
        "\n",
        "                   # Model application\n",
        "                   print(compressed_X_train_scaled.shape)\n",
        "                   regressor = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        "                   regressor.fit(compressed_X_train_scaled, y_train)\n",
        "\n",
        "                   # Generate predictions\n",
        "                   y_pred_scaled = regressor.predict(compressed_X_test_scaled)\n",
        "\n",
        "                   # performance (mean squared error, mean absolute error, and R-squared score)\n",
        "                   accuracy = accuracy_score(y_test, y_pred_scaled)\n",
        "                   accuracy_list.append(accuracy)\n",
        "                   f1 = f1_score(y_test, y_pred_scaled,average = 'micro')\n",
        "                   f1_list.append(f1)\n",
        "\n",
        "                #store plots\n",
        "                fig = plot_confidence_interval(accuracy_list,method,window_size ,compression,'SC') #plot function call\n",
        "                pdf.savefig(fig)\n",
        "                plt.close(fig)\n",
        "\n",
        "                fig2 = plot_confidence_interval(f1_list,method,window_size ,compression,'RMSE') #plot function call\n",
        "                pdf.savefig(fig2)\n",
        "                plt.close(fig2)\n",
        "\n",
        "                # create a file name based on the method, subset index, stride, and compression\n",
        "                avg_accuracy = np.mean(accuracy_list)\n",
        "                file_name = f\"{method}_window size({window_size})_compression({compression} - ACCURACY SCORES).txt\"\n",
        "                with open(os.path.join(folder_name,stride_folder_name, compression_folder_name, file_name), 'w+') as f:\n",
        "                   f.write(f\"Average accuracy Score: {avg_accuracy}\\n\")\n",
        "                   content = str(accuracy_list)\n",
        "                   f.write(content)\n",
        "                   f.close()\n",
        "\n",
        "                avg_f1 = np.mean(f1_list)\n",
        "                file_name = f\"{method}_window size({window_size})_compression({compression} - f1 SCORES).txt\"\n",
        "                with open(os.path.join(folder_name,stride_folder_name, compression_folder_name, file_name), 'w+') as f:\n",
        "                   f.write(f\"Average f1 Score: {avg_f1}\\n\")\n",
        "                   content = str(f1_list)\n",
        "                   f.write(content)\n",
        "                   f.close()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XZNJgwcGuJbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import sys\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/pump_sensor2.txt', delimiter=',')\n",
        "\n",
        "# encode BROKEN,NORMAL,RECOVERING -> 0,1,2\n",
        "le = LabelEncoder()\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
        "\n",
        "# Discard first row + first two columns\n",
        "df = df.iloc[:, 2:]\n",
        "\n",
        "data = df.to_numpy(dtype='float')\n",
        "\n",
        "# Split features X and target y\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "#print(\"Class counts: \", np.unique(y, return_counts=True))\n",
        "\n",
        "# Fill Nan values based on the mean of each sensor\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# lists to store metrics for each window\n",
        "score_list = []\n",
        "\n",
        "# window size\n",
        "window_size = 128 #@param {type:\"number\"}\n",
        "\n",
        "# Iterate over the windows\n",
        "for i in range(0, len(data)-window_size*2+1, window_size):\n",
        "\n",
        " # Split the data into training and testing sets\n",
        " X_train = X[i:i+window_size, :-1]\n",
        " X_test = X[i+window_size:i+window_size*2, :-1]\n",
        " y_train = y[i:i+window_size]\n",
        " y_test = y[i+window_size:i+window_size*2]\n",
        " #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        " # data scaling\n",
        " sc = MinMaxScaler()\n",
        " X_train_scaled = sc.fit_transform(X_train)\n",
        " X_test_scaled = sc.transform(X_test)\n",
        "\n",
        " # model\n",
        " log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        " log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        " #  predictions\n",
        " y_pred = log_reg.predict(X_test_scaled)\n",
        "\n",
        " # Performance (accuracy and confusion matrix)\n",
        " accuracy = accuracy_score(y_test, y_pred)\n",
        " #conf_mat = confusion_matrix(y_test, y_pred)\n",
        " score_list.append(accuracy)\n",
        " print(\"Accuracy: \", accuracy)\n",
        " #print(\"Confusion Matrix: \")\n",
        "\n"
      ],
      "metadata": {
        "id": "zhrqydnr91ws",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XmZmjxwfj4bT",
        "outputId": "490f4992-b3da-49d3-ac44-0e981d296fcc",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts:  (array([0., 1., 2.]), array([     7, 205836,  14477]))\n",
            "Accuracy:  0.9969135802469136\n",
            "Confusion Matrix: \n",
            "[[    0     2     0]\n",
            " [    0 51326    98]\n",
            " [    0    70  3584]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title WHOLE FILE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "import sys\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/pump_sensor2.txt', delimiter=',')\n",
        "\n",
        "# encode BROKEN,NORMAL,RECOVERING -> 0,1,2\n",
        "le = LabelEncoder()\n",
        "df.iloc[:, -1] = le.fit_transform(df.iloc[:, -1])\n",
        "\n",
        "# Discard first row + first two columns\n",
        "df = df.iloc[:, 2:]\n",
        "\n",
        "data = df.to_numpy(dtype='float')\n",
        "\n",
        "# Split features X and target y\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "#print(\"Class counts: \", np.unique(y, return_counts=True))\n",
        "\n",
        "# Fill Nan values based on the mean of each sensor\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
        "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# data scaling\n",
        "sc = MinMaxScaler()\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "X_test_scaled = sc.transform(X_test)\n",
        "\n",
        "# model\n",
        "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# predictions\n",
        "y_pred = log_reg.predict(X_test_scaled)\n",
        "\n",
        "# Performance (accuracy and confusion matrix)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(conf_mat)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "labels = ['BROKEN', 'NORMAL', 'RECOVERING']\n",
        "plt.imshow(conf_mat, cmap=plt.cm.Reds)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xticks([0,1,2], labels, rotation=45)\n",
        "plt.yticks([0,1,2], labels)\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ]
    }
  ]
}